"""Test suite for the TypedModelStrategy in QuickLLM."""

from typing import Callable
from langchain_core.language_models import BaseChatModel, FakeListChatModel
from pytest_mock import MockFixture

from quick_llm import ChainFactory
from quick_llm.strategies import TypedModelStrategy
from ..test_models import TestOutput, TestOutputDictionary


class TestAdaptLLM:
    """Test suite for validating the adaptation of Large Language Models (LLMs)
    to support structured output using the TypedModelStrategy and ensuring proper handling
    for both Pydantic models and dictionary-based models.
    """

    def __with_structured_output_support[T](
        self, mocker: MockFixture, model: type[T], response_lambda: Callable[[str], T]
    ) -> list:
        """Adapt a mocked LLM with structured output support to produce the desired structured output.

        This helper method ensures that the TypedModelStrategy properly adapts a mocked LLM
        that supports the `with_structured_output` method. It invokes the adapted strategy's
        runner multiple times and verifies that the structured output matches the provided model type.

        Args:
            mocker (MockFixture): A pytest-mock fixture used to create and manipulate mocked objects.
            model (type[T]): The target model type to which the LLM output will be adapted.
            response_lambda (Callable[[str], T]): A lambda function providing the structured output
                based on the input prompt.

        Returns:
            list: A list of outputs generated by the adapted LLM runner, matching the specified model type.
        """
        # Mock a llm that returns structured output
        structured_llm = mocker.Mock()
        structured_llm.invoke.side_effect = response_lambda
        # Mock the BaseChatModel to have with_structured_output method
        mocked_llm = mocker.MagicMock(spec=BaseChatModel)
        mocked_llm.with_structured_output.return_value = structured_llm

        factory = (
            ChainFactory(model)
            .use_language_model(mocked_llm)
            .use_structured_output(model)
        )
        strategy = TypedModelStrategy(factory)
        runner = strategy.adapted_llm

        # Check that with_structured_output was called
        mocked_llm.with_structured_output.assert_called_once_with(TestOutput)

        return [runner.invoke("Test prompt 1"), runner.invoke("Test prompt 2")]

    def test_supported_pydantic_model(self, mocker: MockFixture):
        """Test that the TypedModelStrategy correctly adapts an LLM with structured output support.

        This test verifies that when an LLM with the `with_structured_output` method is provided:
        - The method is called with the correct arguments.
        - The adapted runner produces the expected structured output.
        - The output matches the TestOutput model in type and content.
        """
        response = self.__with_structured_output_support(
            mocker, TestOutput, lambda prompt: TestOutput(answer=f"Answer {prompt[-1]}")
        )
        # Verify instances and content
        assert isinstance(response[0], TestOutput)
        assert response[0].answer == "Answer 1"
        assert isinstance(response[1], TestOutput)
        assert response[1].answer == "Answer 2"

    def test_supported_dictionary_model(self, mocker: MockFixture):
        """Test that the TypedModelStrategy correctly adapts an LLM with structured output support.

        This test verifies that when an LLM with the `with_structured_output` method is provided:
        - The method is called with the correct arguments.
        - The adapted runner produces the expected structured output.
        - The output matches the TestOutput model in type and content.
        """
        response = self.__with_structured_output_support(
            mocker, TestOutput, lambda prompt: {"answer": f"Answer {prompt[-1]}"}
        )
        # Verify instances and content
        assert isinstance(response[0], dict)
        assert response[0]["answer"] == "Answer 1"
        assert isinstance(response[1], dict)
        assert response[1]["answer"] == "Answer 2"

    def __without_structured_output_support[T](self, model: type[T]) -> list:
        """Adapt an LLM without structured output support to produce the desired structured output.

        This helper method verifies that the TypedModelStrategy can adapt a
        Large Language Model (LLM) that doesn't natively support producing structured output,
        ensuring the output matches the expected model type and structure.

        Args:
            model (type[T]): The target model type to which the LLM output will be adapted.

        Returns:
            list: A list of outputs generated by the adapted LLM, matching the specified model type.
        """
        base_llm = FakeListChatModel(
            responses=['{"answer": "Answer 1"}', '{"answer": "Answer 2"}']
        )
        factory = (
            ChainFactory(model)
            .use_language_model(base_llm)
            .use_structured_output(model)
        )
        strategy = TypedModelStrategy(factory)
        runner = strategy.adapted_llm

        return [runner.invoke("Test prompt 1"), runner.invoke("Test prompt 2")]

    def test_not_supported_pydantic_model(self):
        """Test that the TypedModelStrategy correctly adapts an LLM with structured output support.

        This test verifies that when an LLM with the `with_structured_output` method is provided:
        - The method is called with the correct arguments.
        - The adapted runner produces the expected structured output.
        - The output matches the TestOutput model in type and content.
        """
        response = self.__without_structured_output_support(TestOutput)
        # Verify instances and content
        assert isinstance(response[0], TestOutput)
        assert response[0].answer == "Answer 1"
        assert isinstance(response[1], TestOutput)
        assert response[1].answer == "Answer 2"

    def test_not_supported_dictionary_model(self):
        """Test that the TypedModelStrategy correctly adapts an LLM with structured output support.

        This test verifies that when an LLM with the `with_structured_output` method is provided:
        - The method is called with the correct arguments.
        - The adapted runner produces the expected structured output.
        - The output matches the TestOutput model in type and content.
        """
        response = self.__without_structured_output_support(TestOutputDictionary)
        # Verify instances and content
        assert isinstance(response[0], dict)
        assert response[0]["answer"] == "Answer 1"
        assert isinstance(response[1], dict)
        assert response[1]["answer"] == "Answer 2"
